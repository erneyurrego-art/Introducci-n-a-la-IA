{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erneyurrego-art/Introducci-n-a-la-IA/blob/main/99%20-%20modelo%20soluci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4Ic045bhyO-"
      },
      "source": [
        "# Modelo de Machine Learning - Entrenamiento con CatBoostClassifier\n",
        "\n",
        "En este Colab se desarrollará todo el ciclo de vida de un modelo de machine learning: desde la inspección de los datos, pasando por la limpieza y transformación, hasta llegar al entrenamiento del modelo. Finalmente, se generará un archivo CSV para enviarlo a la competencia de Kaggle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oitCpoTT2R4R"
      },
      "source": [
        "## Inspección de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVcNcZtO3Brz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder, TargetEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGF_sI1f3IKh"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    d = pd.read_csv('train.csv', on_bad_lines='skip')\n",
        "    display(d.head())\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1N7VYr1e3NKO"
      },
      "outputs": [],
      "source": [
        "d.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-n8I7gf4fSj"
      },
      "outputs": [],
      "source": [
        "# distribución de la variable objetivo por el estracto de la vivienda\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x =\"F_ESTRATOVIVIENDA\", hue=\"RENDIMIENTO_GLOBAL\", data=d, palette=\"Paired\")\n",
        "plt.title(\"Distribución de la variable RENDIMIENTO_GLOBAL por F_ESTRATOVIVIENDA\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlGfVJBQ5Fkq"
      },
      "outputs": [],
      "source": [
        "# Distribución de las variables categoricas del dataset\n",
        "\n",
        "for i, col in enumerate(d.select_dtypes(include=[\"object\"]).columns):\n",
        "\n",
        "  if i == 0:\n",
        "    continue # la distribución de E_PRGM_ACADEMICO necesita transformación\n",
        "\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  sns.countplot(data=d, x=col, order=d[col].value_counts().index, color=\"skyblue\", edgecolor=\"black\")\n",
        "  plt.title(f\"Distribución de la variable cualitativa {col}\")\n",
        "  plt.xticks(rotation=45)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmvjLbJv5qQw"
      },
      "outputs": [],
      "source": [
        "# Mapa de correlapción\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(d.corr(numeric_only=True), cmap=\"coolwarm\", center=0)\n",
        "plt.title(\"Correlación entre las variables cuantitativas\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGIkLTFqvpPl"
      },
      "source": [
        "## Limpieza y transformación función\n",
        "\n",
        "al realizar la limpieza del dataset de train y de test cree una función que se encarga de hacer la limpia total de ambos datsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5yms7KMqskt"
      },
      "outputs": [],
      "source": [
        "print((d.isnull().mean() * 100)[d.isnull().mean() > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nai-kNTRv6Dz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "def clean_dataset(d: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    d = d.drop(columns=[\"ID\"], errors=\"ignore\")\n",
        "\n",
        "    # listado de columnas que se rellenaran con la moda\n",
        "    cols_mode = [\n",
        "        \"E_VALORMATRICULAUNIVERSIDAD\",\n",
        "        \"E_HORASSEMANATRABJA\",\n",
        "        \"F_ESTRATOVIVIENDA\",\n",
        "        \"F_EDUCACIONPADRE\",\n",
        "        \"F_TIENELAVADORA\",\n",
        "        \"F_TIENEAUTOMOVIL\",\n",
        "        \"E_PAGOMATRICULAPROPIO\",\n",
        "        \"F_TIENECOMPUTADOR\",\n",
        "        \"F_TIENEINTERNET.1\",\n",
        "        \"F_EDUCACIONMADRE\",\n",
        "        \"E_HORASSEMANATRABAJA\",\n",
        "    ]\n",
        "\n",
        "    for col in cols_mode:\n",
        "        if col in d.columns:\n",
        "            d[col] = d[col].fillna(d[col].mode()[0])\n",
        "\n",
        "    if \"F_TIENEINTERNET\" in d.columns and \"F_ESTRATOVIVIENDA\" in d.columns:\n",
        "        percentage_if = d[\"F_TIENEINTERNET\"].value_counts(normalize=True).get(\"Si\", 0)\n",
        "\n",
        "        def assign_internet(row):\n",
        "            if pd.notna(row[\"F_TIENEINTERNET\"]):\n",
        "                return row[\"F_TIENEINTERNET\"]\n",
        "\n",
        "            strata = row[\"F_ESTRATOVIVIENDA\"]\n",
        "            upper_strata = [\"Estrato 3\", \"Estrato 4\", \"Estrato 5\", \"Estrato 6\"]\n",
        "\n",
        "            if strata in upper_strata:\n",
        "                return \"Si\"\n",
        "            else:\n",
        "                return \"Si\" if random.random() <= percentage_if else \"No\"\n",
        "\n",
        "        d[\"F_TIENEINTERNET\"] = d.apply(assign_internet, axis=1)\n",
        "\n",
        "    # Crear relaciones de algunas variables para mejorar la predicción del modelo\n",
        "    d['RELA_PROG_VALOR_MATRICULA'] = d.apply(lambda x: f\"{x['E_PRGM_ACADEMICO']}_{x['E_VALORMATRICULAUNIVERSIDAD']}\", axis=1)\n",
        "    d['RELA_PROG_VALOR_MATRICULA_DEPARTAMENTO'] = d.apply(lambda x: f\"{x['E_PRGM_ACADEMICO']}_{x['E_VALORMATRICULAUNIVERSIDAD']}_{x['E_PRGM_DEPARTAMENTO']}\", axis=1)\n",
        "    d['RELA_PROG_DEPARTAMENTO'] = d.apply(lambda x: f\"{x['E_PRGM_ACADEMICO']}_{x['E_PRGM_DEPARTAMENTO']}\", axis=1)\n",
        "\n",
        "\n",
        "\n",
        "    # hacer conversion de la variable objetivo\n",
        "    if 'RENDIMIENTO_GLOBAL' in d.columns:\n",
        "      try:\n",
        "          orden_rendimiento = {'bajo': 0, 'medio-bajo': 1, 'medio-alto': 2, 'alto': 3}\n",
        "          d['RENDIMIENTO_GLOBAL'] = d['RENDIMIENTO_GLOBAL'].replace(orden_rendimiento)\n",
        "      except Exception as e:\n",
        "          print(\"Ocurrío un error al transformar la variable RENDIMIENTO_GLOBAL\")\n",
        "\n",
        "    return d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9OGF8cXiXNA"
      },
      "source": [
        "## Entrenamiento y construcción del modelo de machine learning con el algoritmo de HistGradientBoosting\n",
        "\n",
        "1. Creación del modelo.\n",
        "2. Entrenamiento.\n",
        "3. Predicción.\n",
        "4. Accurracy and score del modelo con test.\n",
        "5. CSV solución para Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBiyajgPEJPB"
      },
      "outputs": [],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKYiZv_due1t"
      },
      "outputs": [],
      "source": [
        "d = clean_dataset(d) # limpiar y transformar el dataset con función anterior.\n",
        "d.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cFHuAsCvQit"
      },
      "outputs": [],
      "source": [
        "d.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si3vtE7SEWNl"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X = d.drop('RENDIMIENTO_GLOBAL', axis=1)\n",
        "y = d['RENDIMIENTO_GLOBAL']\n",
        "\n",
        "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "xtr, xts, ytr, yts = train_test_split(X, y, test_size=0.2, random_state=16, stratify=y)\n",
        "\n",
        "print(\"Tamaño del dataset original: \", d.shape)\n",
        "print(\"Tamaño del dataset de entrenamiento: \", xtr.shape)\n",
        "print(\"Tamaño del dataset de test: \", xts.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKqzPayd1ZZQ"
      },
      "outputs": [],
      "source": [
        "print((d.isnull().mean() * 100)[d.isnull().mean() > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4gfeve2wjwX",
        "outputId": "fd2071c4-4e8a-4135-dd13-d66b9b8ab3d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.4028953\ttest: 0.4062775\tbest: 0.4062775 (0)\ttotal: 6.44s\tremaining: 1h 47m 14s\n",
            "100:\tlearn: 0.4381214\ttest: 0.4392188\tbest: 0.4393270 (99)\ttotal: 9m 25s\tremaining: 1h 23m 51s\n",
            "200:\tlearn: 0.4428412\ttest: 0.4433121\tbest: 0.4433985 (197)\ttotal: 19m 31s\tremaining: 1h 17m 37s\n",
            "300:\tlearn: 0.4455128\ttest: 0.4444632\tbest: 0.4446675 (269)\ttotal: 29m 53s\tremaining: 1h 9m 25s\n",
            "400:\tlearn: 0.4471178\ttest: 0.4449247\tbest: 0.4451638 (380)\ttotal: 39m 51s\tremaining: 59m 32s\n",
            "500:\tlearn: 0.4484945\ttest: 0.4450684\tbest: 0.4451638 (380)\ttotal: 49m 58s\tremaining: 49m 46s\n"
          ]
        }
      ],
      "source": [
        "model = CatBoostClassifier(\n",
        "    iterations=1000,\n",
        "    learning_rate=0.07,\n",
        "    depth=6,\n",
        "    l2_leaf_reg=3,\n",
        "    bootstrap_type='Bernoulli',\n",
        "    subsample=0.75,\n",
        "    auto_class_weights='Balanced',\n",
        "    thread_count=4,\n",
        "    verbose=100,\n",
        "    task_type='CPU',\n",
        "    eval_metric='Accuracy',\n",
        ")\n",
        "\n",
        "model.fit(xtr, ytr, eval_set=(xts, yts), cat_features=categorical_features, use_best_model=True)\n",
        "\n",
        "# Predicción del dataset de test\n",
        "y_pred = model.predict(xts)\n",
        "\n",
        "# Resultados del modelo\n",
        "accuracy = accuracy_score(yts, y_pred)\n",
        "print(f\"Precisión del modelo: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LlGKCIZwur9"
      },
      "source": [
        "### Predicción para la competencia con el test\n",
        "\n",
        "Luego de completar la etapa de entrenamiento, pasamos a la parte de predecir el dataset de test para subirlo a la competencia de Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcEHHl_QlES2"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv(\"test.csv\", on_bad_lines=\"skip\")\n",
        "\n",
        "test_ids = test[\"ID\"]\n",
        "clean_test = clean_dataset(test)\n",
        "\n",
        "pred_final = model.predict(clean_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRbah9ixyLEU"
      },
      "outputs": [],
      "source": [
        "mapping = {'bajo': 0, 'medio-bajo': 1, 'medio-alto': 2, 'alto': 3}\n",
        "reverse_mapping = {v: k for k, v in mapping.items()}\n",
        "final_predictions = [reverse_mapping[p[0]] for p in pred_final]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WiVU8_kx8hh"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({\n",
        "    \"ID\": test_ids,\n",
        "    \"RENDIMIENTO_GLOBAL\": final_predictions\n",
        "})\n",
        "\n",
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiOH5lbKMpEA"
      },
      "outputs": [],
      "source": [
        "submission.to_csv(\"submission.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1Ug+JF1WRUsRutU3zgjyF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}